<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Welcome to qxdn Blog</title>
    <url>/2020/10/17/helloworld/</url>
    <content><![CDATA[<blockquote>
<p>这是一切的开始</p>
</blockquote>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>保研后无所事事，同时想起来自己的GitHub Page一直没有用过，因此借用了<a href="https://github.com/Huxpro">Huxpro</a>的<a href="https://github.com/Huxpro/huxpro.github.io">Hux Blog</a>来搭建自己的GitHub page</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>Hello World</p>
<p>这里是<a href="https://github.com/qxdn">qxdn</a>的Blog，也是第一篇Blog</p>
]]></content>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>电赛</title>
    <url>/2020/10/19/electronicDesignContest/</url>
    <content><![CDATA[<blockquote>
<p>简单回忆电赛</p>
</blockquote>
<h2 id="电赛选题"><a href="#电赛选题" class="headerlink" title="电赛选题"></a>电赛选题</h2><p>我作为组长和<a href="https://github.com/while0l1">李志豪</a>、<a href="https://github.com/renruiwhut">任睿</a>一起参加了2019年的电赛。说到组长的选择其实也是很随意，就是投骰子比小，最小的做组长。2019年的题目可以见<a href="https://www.nuedc-training.com.cn/index/news/details/new_id/154.html">这里</a>，我们当时主要在F题和H题里面纠结，我主张F题，而李志豪强烈反对，因为我们缺少传感器，而且一时没有解决方法，因此我们选择了H题。</p>
<span id="more"></span>

<h2 id="题目要求"><a href="#题目要求" class="headerlink" title="题目要求"></a>题目要求</h2><p>题目的具体要求和测试结果见<a href="https://www.nuedc-training.com.cn/index/news/details/new_id/153">这</a></p>
<p><img src="/images/electronicDesignContest/problem.png" alt="参考图片"></p>
<h3 id="基本要求"><a href="#基本要求" class="headerlink" title="基本要求"></a>基本要求</h3><ol>
<li>电磁炮能够将弹丸射出炮口。</li>
<li>环形靶放置在靶心距离定标点200~300cm间，且在中心轴线上的位置处，键盘输入距离d值，电磁炮将弹丸发射至该位置，距离偏差的绝对值不大于50cm。</li>
<li>用键盘给电磁炮输入环形靶中心与定标点的距离d 及与中心轴线的偏离角度a，一键启动后，电磁炮自动瞄准射击，按击中环形靶环数计分；若脱靶则不计分。</li>
</ol>
<h3 id="发挥部分"><a href="#发挥部分" class="headerlink" title="发挥部分"></a>发挥部分</h3><ol>
<li>在指定范围内任意位置放置环形靶（有引导标识，参见说明2），一键启动后，电磁炮自动搜寻目标并炮击环形靶，按击中环形靶环数计分，完成时间≤30s。</li>
<li>环形靶与引导标识一同放置在距离定标点d=250cm 的弧线上（以靶心定位），引导标识处于最远位置。电磁炮放置在定标点，炮管水平方向与中轴线夹角a =-30°、仰角0°。一键启动电磁炮，炮管在水平方向与中轴线夹角a从-30°至30°、再返回-30°做往复转动，在转动过程中（中途不得停顿）电磁炮自动搜寻目标并炮击环形靶，按击中环形靶环数计分，启动至击发完成时间≤10s。</li>
<li>其他。</li>
</ol>
<h2 id="制作电磁炮"><a href="#制作电磁炮" class="headerlink" title="制作电磁炮"></a>制作电磁炮</h2><p>使用漆包线包裹发射管，我们制作了电磁炮的炮管。使用Boost电路制作升压，电容来存储能量。关于控制电磁炮发射距离使用的是固定发射电压、调整发射角度的方法，使用的方法是使用MATLAB进行数据拟合。测量距离使用openmv中距离和像素的大小成反比的关系。系统结构图、DC-DC电路如下图所示。<br><img src="/images/electronicDesignContest/structure.png" alt="系统结构图"><br><img src="/images/electronicDesignContest/DC-DC.png" alt="DC-DC"></p>
<h2 id="实物"><a href="#实物" class="headerlink" title="实物"></a>实物</h2><p><img src="/images/electronicDesignContest/railgun.jpg" alt="railgun"></p>
<h2 id="报告"><a href="#报告" class="headerlink" title="报告"></a>报告</h2><p><a href="/others/railgunReport.docx">报告</a></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>我们组的电赛代码在<a href="https://github.com/qxdn/BIg-Ivan">这</a>，取名大伊万（笑）。这里面还包含一些训练时期的项目，都在git分支里面。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>在省赛和国赛的时候都打了全十环（不得不说运气真好），然后公费去上海同济玩了几天。最终结果就是获得了一个H题的国一了，不算国家奖学金的话，这是我获得的第一个竞赛国奖。<br><img src="/images/electronicDesignContest/edc.jpg" alt="同济现场"></p>
]]></content>
      <tags>
        <tag>电赛</tag>
        <tag>C</tag>
        <tag>C++</tag>
        <tag>软件</tag>
        <tag>硬件</tag>
      </tags>
  </entry>
  <entry>
    <title>电赛准备</title>
    <url>/2020/10/19/electronicDesignContestPerpare/</url>
    <content><![CDATA[<blockquote>
<p>主要为实验室中的一些经历</p>
</blockquote>
<span id="more"></span>
<h2 id="进入606实验室"><a href="#进入606实验室" class="headerlink" title="进入606实验室"></a>进入606实验室</h2><p>&ensp;&ensp;加入实验室需要经过笔试以及面试。招生时间通常为大一下到大二上这段时间。笔试期间主要为《电路分析》、《模拟电子技术基础》和《数字电子技术基础》里面的知识，还包括单片机、C语音以及IDE的一些知识。面试主要看一些个人项目。我主要展示了一些在403实验室制作的水温控制系统、万年历还有个人制作的简易示波器（因为当时对ADC不是很熟练，而且不知道奈奎斯特抽样定理，所以做的很尴尬）。进入实验室后和学长进行双选，因为当时和张俊伟、李洋一起被分配做电源，所以找了余世民学长做电源。</p>
<h2 id="606实验室学习"><a href="#606实验室学习" class="headerlink" title="606实验室学习"></a>606实验室学习</h2><p>&ensp;&ensp;在实验室的上半个学期主要为学习，以及完成实验室的任务。实验室有着淘汰机制，没有完成阶段任务，在最后就会被淘汰。阶段任务主要为三极管放大电路、运放电路、滤波器等。虽然题目看起来简单，但是实际做起来还是与书上的理想情况不一样。幸好最后没有被淘汰。</p>
<h2 id="转为控制组"><a href="#转为控制组" class="headerlink" title="转为控制组"></a>转为控制组</h2><p>&ensp;&ensp;在一段时间的电源制作（其实没有）后，我反而对控制题目比较感兴趣，就加入了<a href="https://github.com/while0l1">李志豪</a>、<a href="https://github.com/renruiwhut">任睿</a>的小组，一起做控制题。制作了一阶倒立摆、自由摆、板球控制系统、麦克纳姆轮四轮车、悬挂系统、风力摆、二轮循迹平衡车、XY写字机器人等项目。</p>
<h2 id="实物图片"><a href="#实物图片" class="headerlink" title="实物图片"></a>实物图片</h2><p><img src="/images/electronicDesignContestPrepare/flb.gif" alt="风力摆"><br><img src="/images/electronicDesignContestPrepare/balanceCar.gif" alt="二轮平衡车"><br><img src="/images/electronicDesignContestPrepare/XYWriter.gif" alt="XY写字机器人"></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>&ensp;&ensp;这些就是我们组在电赛期间的一些准备内容，代码主要在<a href="https://github.com/while0l1/stm32f4_modules">代码1</a>和<a href="https://github.com/qxdn/MYDS">代码2</a>和<a href="https://github.com/qxdn/BIg-Ivan">训练代码</a></p>
]]></content>
      <tags>
        <tag>电赛</tag>
        <tag>C</tag>
        <tag>C++</tag>
        <tag>软件</tag>
        <tag>硬件</tag>
      </tags>
  </entry>
  <entry>
    <title>节能减排</title>
    <url>/2020/10/19/energySaving/</url>
    <content><![CDATA[<blockquote>
<p>节能减排大赛的记录</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>原先的校内初选中，我最先参加的与能动学院一起的节能减排做纵倾优化的船，但是没有通过初审。于是和汪博文、赵之清、胡群强、王瑞林、任睿、孙文滨一起参加节能减排大赛，制作光伏屋顶。</p>
<span id="more"></span>

<h2 id="研制背景"><a href="#研制背景" class="headerlink" title="研制背景"></a>研制背景</h2><p>传统光伏屋顶的发电效率比较低，因此我们考虑将一部分光伏板换成天窗使用。由于天窗会有灰尘雨水等，比较容易脏，需要人力清除成本。因此我们对天窗挡板做智能处理，能够根据天气光照自动控制开合角度，使得光照最大化同时减少人力清理成本。根据贾博文老师说，这个貌似是根据他在新加坡看到的直接更改的。</p>
<h2 id="实物"><a href="#实物" class="headerlink" title="实物"></a>实物</h2><p>我们主要制作了<a href="http://101.133.235.188/">智能设计平台</a>(现在应该上不去了)、手机控制平台和光伏屋顶。三个之间的通信主要是使用MQTT协议。<br><img src="/images/energySavingContest/design.png" alt="智能设计网页"><br><img src="/images/energySavingContest/controller.png" alt="智能控制平台"><br><img src="/images/energySavingContest/roof.gif" alt="光伏屋顶"></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><a href="https://github.com/qxdn/sunbest">智能设计平台</a>、<a href="https://github.com/qxdn/WindowController">天窗控制平台</a>和<a href="https://github.com/qxdn/EnergySaveRoof">实物与8266代码</a>因为疫情原因而且组员也不是很会因此实物代码比较老、但是8266的代码是最新的。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>最后还是只得了一个国三，如果再做的好一点也许就能过了网申冲击国二、国一了。</p>
]]></content>
      <tags>
        <tag>C</tag>
        <tag>C++</tag>
        <tag>软件</tag>
        <tag>硬件</tag>
        <tag>节能减排</tag>
        <tag>java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>用AlexNet实现DogsVsCats</title>
    <url>/2020/10/22/DogsVsCatsAlexNet/</url>
    <content><![CDATA[<blockquote>
<p>AlexNet实现猫狗大战</p>
</blockquote>
<span id="more"></span>
<h2 id="AlexNet-实现猫狗大战"><a href="#AlexNet-实现猫狗大战" class="headerlink" title="AlexNet 实现猫狗大战"></a>AlexNet 实现猫狗大战</h2><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>早就听说过tensorflow的大名，但一直没有时间仔细研究，而且一直缺少数据集，也就没怎么了解。同时因为那tensorflow1的复杂静态图一直劝退。如今有了时间，而且tensorflow2更加易懂，因此仔细研究了一下，也就是第一次炼丹。首先是在<a href="https://www.kaggle.com/">kaggle</a>下载数据集就难到我了，没想到翻了墙还被困在手机号验证。最后只能借助于微软提供的数据集下载。最开始用自己的CPU跑又慢又卡，自从我换了硬盘加了内存以来，好久都没有这么卡过了。</p>
<p><img src="/images/DogsVsCats/overload.png" alt="overload"></p>
<p>随后换上了Google的<a href="https://colab.research.google.com/notebooks/intro.ipynb#">colab</a>,用了免费GPU才知道GPU的好。</p>
<blockquote>
<p>以下正文</p>
</blockquote>
<h2 id="1、数据准备"><a href="#1、数据准备" class="headerlink" title="1、数据准备"></a>1、数据准备</h2><p>在Colab上需要下载数据和准备环境，已经将数据上传到了Github</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install tensorflow</span><br><span class="line">!wget https://github.com/qxdn/DogsVsCats/releases/download/v1<span class="number">.0</span><span class="number">.0</span>/data.<span class="built_in">zip</span></span><br><span class="line">!unzip data.<span class="built_in">zip</span></span><br><span class="line">!rm -rf data.<span class="built_in">zip</span></span><br></pre></td></tr></table></figure>

<p>AlexNet的输入是<code>[227,227,3]</code>，因此要对输入进行预处理，使得符合规范，同时还需要进行贴标签(dog=1,cat=0)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">125</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span>(<span class="params">img_path,size=(<span class="params"><span class="number">227</span>,<span class="number">227</span></span>)</span>):</span></span><br><span class="line">    label = tf.constant(<span class="number">0</span>,tf.int8) <span class="keyword">if</span> tf.strings.regex_full_match(img_path,<span class="string">&quot;.*cat.*&quot;</span>) \</span><br><span class="line">            <span class="keyword">else</span> tf.constant(<span class="number">1</span>,tf.int8)</span><br><span class="line">    img = tf.io.read_file(img_path)</span><br><span class="line">    img = tf.image.decode_jpeg(img) </span><br><span class="line">    img = tf.image.resize(img,size)/<span class="number">255.0</span>  <span class="comment">#转float要归一</span></span><br><span class="line">    <span class="keyword">return</span>(img,label)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用并行化预处理num_parallel_calls 和预存数据prefetch来提升性能</span></span><br><span class="line"><span class="comment"># num_parallel_calls=tf.data.experimental.AUTOTUNE 根据CPU动态处理 未指定就顺序处理</span></span><br><span class="line"><span class="comment">#shuffle 随机重排</span></span><br><span class="line"><span class="comment">#batch()一次出多少</span></span><br><span class="line"><span class="comment">#prefetch 提前取出多少批batch</span></span><br><span class="line">ds_train = tf.data.Dataset.list_files(<span class="string">&quot;./data/train/*.jpg&quot;</span>) \</span><br><span class="line">           .<span class="built_in">map</span>(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \</span><br><span class="line">           .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">           .prefetch(tf.data.experimental.AUTOTUNE)  </span><br><span class="line"></span><br><span class="line">ds_test = tf.data.Dataset.list_files(<span class="string">&quot;./data/test/*.jpg&quot;</span>) \</span><br><span class="line">           .<span class="built_in">map</span>(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \</span><br><span class="line">           .batch(BATCH_SIZE) \</span><br><span class="line">           .prefetch(tf.data.experimental.AUTOTUNE)  </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">&#x27;svg&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看训练样本</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))  <span class="comment">#8*8 inch</span></span><br><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ds_train.unbatch().take(<span class="number">9</span>)):  <span class="comment">#enumerate 组合成索引、数据迭代</span></span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow(img.numpy())</span><br><span class="line">    ax.set_title(<span class="string">&quot;label = %d&quot;</span>%label)</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([]) </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/DogsVsCats/output_7_0.svg"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> ds_train.take(<span class="number">1</span>):</span><br><span class="line">    print(x.shape,y.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(125, 227, 227, 3) (125,)
</code></pre>
<h2 id="2、定义模型"><a href="#2、定义模型" class="headerlink" title="2、定义模型"></a>2、定义模型</h2><p>AlexNet相较于以前的网络主要引入了Relu激活函数、DropOut层和lrn局部响应</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># LRN层</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRN</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LRN, self).__init__()</span><br><span class="line">        self.depth_radius=<span class="number">2</span></span><br><span class="line">        self.bias=<span class="number">1</span></span><br><span class="line">        self.alpha=<span class="number">1e-4</span></span><br><span class="line">        self.beta=<span class="number">0.75</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.lrn(x,depth_radius=self.depth_radius,</span><br><span class="line">                         bias=self.bias,alpha=self.alpha,</span><br><span class="line">                         beta=self.beta)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.keras.backend.clear_session() <span class="comment">#清空会话</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">96</span>,kernel_size=(<span class="number">11</span>,<span class="number">11</span>),activation=<span class="string">&#x27;relu&#x27;</span>,strides=(<span class="number">4</span>,<span class="number">4</span>),input_shape=(<span class="number">227</span>,<span class="number">227</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(LRN())</span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>),activation=<span class="string">&#x27;relu&#x27;</span>,strides=(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(LRN())</span><br><span class="line">model.add(layers.Conv2D(<span class="number">384</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,strides=(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">384</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,strides=(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,strides=(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten()) <span class="comment"># 不要忘记有一层降为一维</span></span><br><span class="line">model.add(layers.Dense(<span class="number">4096</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">4096</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">2</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))  <span class="comment">#真实的AlexNet会分成1000类，此处分2类 sofmax来计算概率</span></span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         
_________________________________________________________________
lrn (LRN)                    (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         
_________________________________________________________________
lrn_1 (LRN)                  (None, 13, 13, 256)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         
_________________________________________________________________
flatten (Flatten)            (None, 9216)              0         
_________________________________________________________________
dense (Dense)                (None, 4096)              37752832  
_________________________________________________________________
dropout (Dropout)            (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              16781312  
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 8194      
=================================================================
Total params: 58,289,538
Trainable params: 58,289,538
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="3、训练模型"><a href="#3、训练模型" class="headerlink" title="3、训练模型"></a>3、训练模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.00001</span>),</span><br><span class="line">        loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">        metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path=<span class="string">&#x27;./checkpoint/AlexNet/AlexNet-&#123;epoch:02d&#125;.ckpt&#x27;</span></span><br><span class="line"><span class="comment">#tf生成ckpt文件时会同步生成索引表，那么通过判断是否有索引表，就知道有没有保存过参数。</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path+<span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    print(<span class="string">&#x27;----------------load the model--------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line">cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                            save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                            save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(ds_train,epochs= <span class="number">20</span>,validation_data=ds_test,</span><br><span class="line">                    callbacks = [cp_callback],workers = <span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
184/184 [==============================] - 40s 219ms/step - loss: 0.6630 - accuracy: 0.5944 - val_loss: 0.6141 - val_accuracy: 0.6615
Epoch 2/20
184/184 [==============================] - 40s 220ms/step - loss: 0.5970 - accuracy: 0.6754 - val_loss: 0.5586 - val_accuracy: 0.7040
Epoch 3/20
184/184 [==============================] - 40s 219ms/step - loss: 0.5426 - accuracy: 0.7244 - val_loss: 0.5088 - val_accuracy: 0.7505
Epoch 4/20
184/184 [==============================] - 40s 219ms/step - loss: 0.4946 - accuracy: 0.7598 - val_loss: 0.4840 - val_accuracy: 0.7735
Epoch 5/20
184/184 [==============================] - 40s 220ms/step - loss: 0.4545 - accuracy: 0.7852 - val_loss: 0.4469 - val_accuracy: 0.8055
Epoch 6/20
184/184 [==============================] - 40s 220ms/step - loss: 0.4207 - accuracy: 0.8064 - val_loss: 0.4180 - val_accuracy: 0.8100
Epoch 7/20
184/184 [==============================] - 40s 219ms/step - loss: 0.3991 - accuracy: 0.8193 - val_loss: 0.4016 - val_accuracy: 0.8250
Epoch 8/20
184/184 [==============================] - 41s 220ms/step - loss: 0.3788 - accuracy: 0.8309 - val_loss: 0.3908 - val_accuracy: 0.8315
Epoch 9/20
184/184 [==============================] - 40s 219ms/step - loss: 0.3587 - accuracy: 0.8427 - val_loss: 0.3733 - val_accuracy: 0.8375
Epoch 10/20
184/184 [==============================] - 38s 207ms/step - loss: 0.3387 - accuracy: 0.8539 - val_loss: 0.3860 - val_accuracy: 0.8345
Epoch 11/20
184/184 [==============================] - 40s 220ms/step - loss: 0.3273 - accuracy: 0.8576 - val_loss: 0.3498 - val_accuracy: 0.8475
Epoch 12/20
184/184 [==============================] - 38s 207ms/step - loss: 0.3064 - accuracy: 0.8676 - val_loss: 0.3671 - val_accuracy: 0.8380
Epoch 13/20
184/184 [==============================] - 38s 208ms/step - loss: 0.2931 - accuracy: 0.8762 - val_loss: 0.3501 - val_accuracy: 0.8495
Epoch 14/20
184/184 [==============================] - 40s 220ms/step - loss: 0.2737 - accuracy: 0.8864 - val_loss: 0.3361 - val_accuracy: 0.8540
Epoch 15/20
184/184 [==============================] - 40s 219ms/step - loss: 0.2694 - accuracy: 0.8890 - val_loss: 0.3311 - val_accuracy: 0.8585
Epoch 16/20
184/184 [==============================] - 38s 208ms/step - loss: 0.2557 - accuracy: 0.8938 - val_loss: 0.3388 - val_accuracy: 0.8565
Epoch 17/20
184/184 [==============================] - 40s 219ms/step - loss: 0.2362 - accuracy: 0.9030 - val_loss: 0.3160 - val_accuracy: 0.8680
Epoch 18/20
184/184 [==============================] - 38s 207ms/step - loss: 0.2184 - accuracy: 0.9106 - val_loss: 0.3692 - val_accuracy: 0.8515
Epoch 19/20
184/184 [==============================] - 38s 207ms/step - loss: 0.2085 - accuracy: 0.9160 - val_loss: 0.3198 - val_accuracy: 0.8710
Epoch 20/20
184/184 [==============================] - 41s 222ms/step - loss: 0.1909 - accuracy: 0.9239 - val_loss: 0.3019 - val_accuracy: 0.8705
</code></pre>
<h2 id="4、评估模型"><a href="#4、评估模型" class="headerlink" title="4、评估模型"></a>4、评估模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">&#x27;svg&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span>(<span class="params">history, metric</span>):</span></span><br><span class="line">    train_metrics = history.history[metric]</span><br><span class="line">    val_metrics = history.history[<span class="string">&#x27;val_&#x27;</span>+metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">&#x27;bo--&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and validation &#x27;</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">&quot;train_&quot;</span>+metric, <span class="string">&#x27;val_&#x27;</span>+metric])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot_metric(history,<span class="string">&quot;loss&quot;</span>) <span class="comment">#结果看可以再练练</span></span><br></pre></td></tr></table></figure>


<p><img src="/images/DogsVsCats/output_16_0.svg"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot_metric(history,<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/images/DogsVsCats/output_17_0.svg"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#可以使用evaluate对数据进行评估</span></span><br><span class="line">val_loss,val_accuracy = model.evaluate(ds_test,workers=<span class="number">4</span>)</span><br><span class="line">print(val_loss,val_accuracy)</span><br></pre></td></tr></table></figure>

<pre><code>16/16 [==============================] - 2s 144ms/step - loss: 0.3019 - accuracy: 0.8705
0.3018629252910614 0.8705000281333923
</code></pre>
<h2 id="5、使用模型"><a href="#5、使用模型" class="headerlink" title="5、使用模型"></a>5、使用模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">perpareImage</span>(<span class="params">img,sizes=(<span class="params">-<span class="number">1</span>,<span class="number">227</span>,<span class="number">227</span>,<span class="number">3</span></span>)</span>):</span></span><br><span class="line">  img = tf.reshape(img,shape=sizes)</span><br><span class="line">  <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ds_test.unbatch().take(<span class="number">1</span>)):</span><br><span class="line">  img=tf.reshape(img,shape=(-<span class="number">1</span>,<span class="number">227</span>,<span class="number">227</span>,<span class="number">3</span>))</span><br><span class="line">  p=model.predict(img)</span><br><span class="line">  print(p)</span><br><span class="line">  p=tf.argmax(p,<span class="number">1</span>)</span><br><span class="line">  print(p)</span><br><span class="line">  print(p.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.91607434 0.08392565]]
tf.Tensor([0], shape=(1,), dtype=int64)
(1,)
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">&#x27;svg&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看训练样本</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))  <span class="comment">#8*8 inch</span></span><br><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ds_test.unbatch().take(<span class="number">9</span>)):  <span class="comment">#enumerate 组合成索引、数据迭代</span></span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow(img.numpy())</span><br><span class="line">    predict = model.predict(perpareImage(img))</span><br><span class="line">    ax.set_title(<span class="string">&quot;predict=%d,label=%d&quot;</span>%(tf.argmax(predict,<span class="number">1</span>),label))</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([]) </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/DogsVsCats/output_22_0.svg"></p>
<h2 id="6、保存模型"><a href="#6、保存模型" class="headerlink" title="6、保存模型"></a>6、保存模型</h2><p>tensorflow原生保存</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署</span></span><br><span class="line"></span><br><span class="line">model.save(<span class="string">&#x27;./model/tf_AlexNet_Model&#x27;</span>, save_format=<span class="string">&quot;tf&quot;</span>)</span><br><span class="line">print(<span class="string">&#x27;export saved model.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model_loaded = tf.keras.models.load_model(<span class="string">&#x27;./model/tf_AlexNet_Model&#x27;</span>)</span><br><span class="line">model_loaded.evaluate(ds_test)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: ./model/tf_AlexNet_Model/assets
export saved model.
16/16 [==============================] - 2s 147ms/step - loss: 0.3019 - accuracy: 0.5155





[0.301862895488739, 0.515500009059906]
</code></pre>
<h2 id="repo"><a href="#repo" class="headerlink" title="repo"></a>repo</h2><p><a href="https://github.com/qxdn/DogsVsCats">DogsVsCats</a></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>踩的坑有点点多，比如搭建网络时候忘记摊平，预测的时候因为形状不对卡了半天，CPU训练的时候loss和准确度不变，差点以为失败了，不过最后看来还算成功吧。赞美Google Colab。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
        <tag>AlexNet</tag>
      </tags>
  </entry>
  <entry>
    <title>升级到WSL2</title>
    <url>/2020/10/23/upgradeWSL2/</url>
    <content><![CDATA[<blockquote>
<p>将WSL1升级到WSL2</p>
</blockquote>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因为一些个人原因，需要将原先的WSL1升级到WSL2，参考<a href="https://docs.microsoft.com/zh-cn/windows/wsl/install-win10">微软文档</a>，记录踩坑</p>
<h2 id="一、检查版本"><a href="#一、检查版本" class="headerlink" title="一、检查版本"></a>一、检查版本</h2><p>对于x64系统目前的要求是<code>1903</code>或者更高,<code>Build 18362</code>或者更高。使用<code>win+R</code>输入<code>winver</code>来检查自己的版本<br><img src="/images/post-upgradeWSL/version.png" alt="version"></p>
<h2 id="二、启动虚拟机功能"><a href="#二、启动虚拟机功能" class="headerlink" title="二、启动虚拟机功能"></a>二、启动虚拟机功能</h2><p>管理员模式启动powershell输入</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">dism.exe /online /<span class="built_in">enable-feature</span> /featurename:VirtualMachinePlatform /all /norestart</span><br></pre></td></tr></table></figure>
<p><img src="/images/post-upgradeWSL/enableVMFeature.png" alt="启动虚拟机功能"><br><strong>然后重启电脑</strong></p>
<h2 id="三、下载Linux内核升级包"><a href="#三、下载Linux内核升级包" class="headerlink" title="三、下载Linux内核升级包"></a>三、下载Linux内核升级包</h2><p>下载最新<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">升级包</a><br><img src="/images/post-upgradeWSL/package.png" alt="package"></p>
<h2 id="四、设置WSL2作为默认版本"><a href="#四、设置WSL2作为默认版本" class="headerlink" title="四、设置WSL2作为默认版本"></a>四、设置WSL2作为默认版本</h2><p>管理员powershell中运行</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl -<span class="literal">-set</span><span class="literal">-default</span><span class="literal">-version</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h2 id="五、转换WSL"><a href="#五、转换WSL" class="headerlink" title="五、转换WSL"></a>五、转换WSL</h2><p>使用该指令查看wsl状态</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">-l</span> <span class="literal">-v</span></span><br></pre></td></tr></table></figure>
<p>我的输出</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">  NAME      STATE           VERSION</span><br><span class="line">* Ubuntu    Stopped         <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>转换WSL</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl -<span class="literal">-set</span><span class="literal">-version</span> Ubuntu <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">正在进行转换，这可能需要几分钟时间...</span><br><span class="line">有关与 WSL <span class="number">2</span> 的主要区别的信息，请访问 https://aka.ms/wsl2</span><br><span class="line">请启用虚拟机平台 Windows 功能并确保在 BIOS 中启用虚拟化。</span><br><span class="line">有关信息，请访问 https://aka.ms/wsl2<span class="literal">-install</span></span><br></pre></td></tr></table></figure>
<p>这里在我搜索了<a href="https://github.com/microsoft/WSL/issues/5363">issue</a>后发现主要还是Hyper-V、虚拟平台等问题，可以试一试管理员模式运行以下指令</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">DISM /Online /<span class="built_in">Enable-Feature</span> /All /FeatureName:Microsoft<span class="literal">-Hyper</span><span class="literal">-V</span></span><br><span class="line">dism.exe /online /<span class="built_in">enable-feature</span> /featurename:Microsoft<span class="literal">-Windows</span><span class="literal">-Subsystem</span><span class="literal">-Linux</span> /all /norestart</span><br><span class="line">dism.exe /online /<span class="built_in">enable-feature</span> /featurename:VirtualMachinePlatform /all /norestart</span><br><span class="line">bcdedit /<span class="built_in">set</span> hypervisorlaunchtype auto</span><br></pre></td></tr></table></figure>
<p>最主要的应该是</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">DISM /Online /<span class="built_in">Enable-Feature</span> /All /FeatureName:Microsoft<span class="literal">-Hyper</span><span class="literal">-V</span></span><br><span class="line">bcdedit /<span class="built_in">set</span> hypervisorlaunchtype auto</span><br></pre></td></tr></table></figure>

<p>重新转换<br><img src="/images/post-upgradeWSL/converted.png" alt="转换完成"></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>VMware老版本与Hyper-V冲突，得找个时间去更新到最新版本兼容</p>
]]></content>
      <tags>
        <tag>Windows</tag>
        <tag>Linux</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>毕业设计（一）环境搭建</title>
    <url>/2021/01/18/installpytorch/</url>
    <content><![CDATA[<blockquote>
<p>毕设pytorch环境搭建</p>
</blockquote>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>体验过CPU和GPU速度之后，就不会再想使用CPU版本的机器学习框架进行训练。</p>
<h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><p>第一步就是要完成cuda的安装，进入<code>NIVIDA控制面板</code>-&gt;<code>系统信息</code>-&gt;<code>组件</code>，查看<code>3D设置</code>中的<code>NVCUDA64.DLL</code>，这里显示的就是当前显卡驱动所支持的CUDA信息，所要安装的CUDA版本不得大于这里显示的版本。然后前往<a href="https://developer.nvidia.com/zh-cn/cuda-downloads">CUDA官网</a>下载CUDA。建议在下载之前先去其他一些网址看一下支持的CUDA版本，以免到时候重新安装</p>
<ul>
<li><a href="https://tensorflow.google.cn/install/source_windows">tensorflow</a> (换成English可以看最新支持)</li>
<li><a href="https://pytorch.org/get-started/locally/">pytorch</a></li>
</ul>
<p><img src="/images/GraduationProject/GPUInfo.png" alt="GPU信息"></p>
<p>如果发现自己安装的版本没有已经构建好的版本还有两种方法。</p>
<ul>
<li>自行从源码编译，这点不推荐，想起来我之间自己在树莓派上面编译opencv的经历颜文字(ಥ _ ಥ)，强烈不推荐。</li>
<li>卸载重装CUDA</li>
</ul>
<p>重装CUDA比较简单,见下图中的NVIDIA应用除了<code>NVIDIA的图形驱动程序</code>和<code>NVIDIA Physx系统软件</code>都卸载就行。如果下不动的就使用迅雷11，新版迅雷配合网盘简直神一般的体验。</p>
<p><img src="/images/GraduationProject/uninstall.png" alt="GPU信息"></p>
<p>安装完成后可以在命令行里面使用<code>nvcc -V</code>看看结果。</p>
<h2 id="cuDNN安装"><a href="#cuDNN安装" class="headerlink" title="cuDNN安装"></a>cuDNN安装</h2><p>cuDNN安装比较简单，首先进入<a href="https://developer.nvidia.com/rdp/cudnn-archive">官网</a>，选择你安装的CUDA的对应版本即可。下载也需要进行注册，填一个调查问卷，但是因为我实在进不去，就使用迅雷接管下载链接之间下载。将解压后的<code>bin</code>、<code>include</code>、<code>lib</code>三个文件复制进入<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0</code>即可。我安装的版本是<code>8.0.4</code></p>
<h2 id="pytorch安装"><a href="#pytorch安装" class="headerlink" title="pytorch安装"></a>pytorch安装</h2><p>听闻pytorch容易调试，且搭建网络比较快，而我此前只是用过tensorflow2.0中的keras进行过搭建，因此本次毕设初步打算使用pytorch作为工具，也可能不用呢(￣y▽,￣)╭ 。使用pytorch推荐的conda安装方法</p>
<p><code>conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch</code></p>
<p>这里我是使用清华镜像源的，是否要加<code>-c pytorch</code>还是看你的<code>.condarc</code>怎么写的，如果写了<code>custom_channels</code>且里面的<code>pytorch</code>也是用了清华源的可以加，没有的话就去掉<code>-c pytorch</code>，然而我镜像源也下不了（吐了），发现浏览器也下不了，就只能用迅雷接管下载，然后本地安装。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#本地安装</span></span><br><span class="line">conda install --use-local cudatoolkit-11.0.221-h74a9793_0.conda</span><br><span class="line">conda install --use-local pytorch-1.7.1-py3.8_cuda110_cudnn8_0.tar.bz2</span><br></pre></td></tr></table></figure>
<p>然后进行测试<br><img src="/images/GraduationProject/verify.png" alt="verify"></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>环境的搭建就到此为止，安装并不难，只是我没想到我尽然会连镜像源都下不动😩。后续视情况可能会使用GPU服务器，但是现在先在本地收集数据集和预先学习。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>毕业设计</tag>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title>毕业设计（二）darknet编译</title>
    <url>/2021/03/04/builddarknet/</url>
    <content><![CDATA[<blockquote>
<p>win10编译darknet</p>
</blockquote>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>寒假训练了4个版本的yolo，其中yolov4和yolov4-tiny是基于darknet的。由于都是在<a href="https://colab.research.google.com/notebooks/welcome.ipynb">colab</a>上训练的，不好展示，所以打算在win10上跑一下，因此本文旨在win10编译darknet的踩坑记录。</p>
<h2 id="安装Visual-Studio"><a href="#安装Visual-Studio" class="headerlink" title="安装Visual Studio"></a>安装Visual Studio</h2><p>这个不用多说，安装2017或者2019版就行，需要开启英语语言</p>
<h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><p>参考上一篇安装CUDA就行，需要CUDAv10.0以上，并且安装时要点VS集成</p>
<h2 id="vcpkg安装"><a href="#vcpkg安装" class="headerlink" title="vcpkg安装"></a>vcpkg安装</h2><p>参考vcpkg的官方下载方式，<code>powershell</code>中执行如下命令</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/microsoft/vcpkg</span><br><span class="line"><span class="built_in">cd</span> vcpkg</span><br><span class="line">bootstrap<span class="literal">-vcpkg</span>.bat</span><br></pre></td></tr></table></figure>
<p>如果执行<code>bootstrap-vcpkg.bat</code>时，下载<code>vcpkg.exe</code>遇到网络问题，可以直接去<code>release</code>里面下载二进制文件</p>
<h2 id="vcpkg安装依赖"><a href="#vcpkg安装依赖" class="headerlink" title="vcpkg安装依赖"></a>vcpkg安装依赖</h2><p>根据AlexeyAB的repo说明，<code>powershell</code>执行如下命令</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">vcpkg install darknet[<span class="type">full</span>]:x64<span class="literal">-windows</span></span><br></pre></td></tr></table></figure>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><p><strong>事后得知，此处遇到的网络问题可以试一试校园网，校园网似乎对从外网下载文件有较好的效果</strong></p>
<p>安装opencv时，需要从<code>raw.githubusercontent.com</code>下载东西，然而遇到了host问题。首先尝试修改了host，结果遇到了<code>SSL connect error</code>问题，于是在加了几个host发现还是失败了。遂尝试使用VPN代理，按照输出将<code>HTTP_PROXY</code>和<code>HTTPS_PROXY</code>加入到环境变量，依然不行。尝试直接在powershell中使用变量。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$env:HTTPS_PROXY</span>=<span class="string">&quot;https://127.0.0.1:7890/&quot;</span></span><br><span class="line"><span class="variable">$env:HTTP_PROXY</span>=<span class="string">&quot;http://127.0.0.1:7890/&quot;</span></span><br></pre></td></tr></table></figure>
<p>此时的staus输出为</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">Failed. Status: <span class="number">4</span>;<span class="string">&quot;A requested feature, protocol or option was not found built-in in this libcurl due to a build-time decision.&quot;</span></span><br><span class="line"></span><br><span class="line">Failed to download file.</span><br><span class="line"><span class="keyword">If</span> you use a proxy, please <span class="built_in">set</span> the HTTPS_PROXY and HTTP_PROXY environment variables to <span class="string">&quot;https://user:password@your-proxy-ip-address:port/&quot;</span>.</span><br><span class="line"></span><br><span class="line"><span class="keyword">If</span> error with status <span class="number">4</span> (Issue <span class="comment">#15434),</span></span><br><span class="line"><span class="keyword">try</span> setting <span class="string">&quot;http://user:password@your-proxy-ip-address:port/&quot;</span>.</span><br><span class="line"></span><br><span class="line">Otherwise, please submit an issue at https://github.com/Microsoft/vcpkg/issues</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>因此根据要求执行下面代码</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$env:HTTPS_PROXY</span>=<span class="string">&quot;http://127.0.0.1:7890/&quot;</span></span><br></pre></td></tr></table></figure>
<p>此时重新执行安装命令，即可完成下载。</p>
<p>安装opencv时遇到</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CMake Error at scripts&#x2F;cmake&#x2F;vcpkg_execute_build_process.cmake:144 (message):</span><br><span class="line">    Command failed: C:&#x2F;src&#x2F;vcpkg&#x2F;downloads&#x2F;tools&#x2F;cmake-3.19.2-windows&#x2F;cmake-3.19.2-win32-x86&#x2F;bin&#x2F;cmake.exe --build . --config Debug --target install -- -v -j9</span><br><span class="line">    Working Directory: C:&#x2F;src&#x2F;vcpkg&#x2F;buildtrees&#x2F;opencv4&#x2F;x64-windows-dbg</span><br><span class="line">    See logs for more information:</span><br><span class="line">      C:\src\vcpkg\buildtrees\opencv4\install-x64-windows-dbg-out.log</span><br><span class="line"></span><br><span class="line">Call Stack (most recent call first):</span><br><span class="line">  scripts&#x2F;cmake&#x2F;vcpkg_build_cmake.cmake:96 (vcpkg_execute_build_process)</span><br><span class="line">  scripts&#x2F;cmake&#x2F;vcpkg_install_cmake.cmake:27 (vcpkg_build_cmake)</span><br><span class="line">  ports&#x2F;opencv4&#x2F;portfile.cmake:385 (vcpkg_install_cmake)</span><br><span class="line">  scripts&#x2F;ports.cmake:133 (include)</span><br></pre></td></tr></table></figure>
<p>尝试如下指令</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">vcpkg install darknet[<span class="type">opencv</span>-<span class="type">base</span>,<span class="type">cuda</span>,<span class="type">cudnn</span>]:x64<span class="literal">-windows</span></span><br></pre></td></tr></table></figure>


<h2 id="编译darknet"><a href="#编译darknet" class="headerlink" title="编译darknet"></a>编译darknet</h2><p>提前安装<a href="https://github.com/ninja-build/ninja">ninja</a>并添加到环境变量</p>
<p>修改<code>Makefile</code></p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">GPU=1</span><br><span class="line">CUDNN=1</span><br><span class="line">CUDNN_HALF=1</span><br><span class="line">OPENCV=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#我是gtx1050，根据makefile里面的注释自己的修改</span></span><br><span class="line">ARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61 </span><br></pre></td></tr></table></figure>

<p>按照AlexeyAB的repo，执行如下代码，注意CMake的版本，过低将无法编译。注意下面的顺序，如果有问题需要清理一下缓存，不然会一直编译失败</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$env:VCPKG_ROOT</span>=<span class="string">&quot;vcpkg的位置&quot;</span></span><br><span class="line">git clone https://github.com/AlexeyAB/darknet</span><br><span class="line"><span class="built_in">cd</span> darknet</span><br><span class="line">powershell <span class="literal">-ExecutionPolicy</span> Bypass <span class="operator">-File</span> .\build.ps1</span><br></pre></td></tr></table></figure>

<p>如果正确执行上述步骤的话，编译是不会出错的</p>
<h2 id="测试darknet"><a href="#测试darknet" class="headerlink" title="测试darknet"></a>测试darknet</h2><h3 id="原图"><a href="#原图" class="headerlink" title="原图"></a>原图</h3><p><img src="/images/GraduationProject/origin.jpg" alt="origin"></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">darknet.exe detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights origin.jpg  <span class="literal">-thresh</span> <span class="number">0.25</span></span><br></pre></td></tr></table></figure>
<h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA-version: 11000 (11000), cuDNN: 8.0.4, GPU count: 1  </span><br><span class="line"> OpenCV version: 4.5.1</span><br><span class="line"> 0 : compute_capability &#x3D; 610, cudnn_half &#x3D; 0, GPU: GeForce GTX 1050 </span><br><span class="line">net.optimized_memory &#x3D; 0 </span><br><span class="line">mini_batch &#x3D; 1, batch &#x3D; 8, time_steps &#x3D; 1, train &#x3D; 0</span><br><span class="line">   layer   filters  size&#x2F;strd(dil)      input                output</span><br><span class="line">   0 Create CUDA-stream - 0</span><br><span class="line"> Create cudnn-handle 0 </span><br><span class="line">conv     32       3 x 3&#x2F; 1    608 x 608 x   3 -&gt;  608 x 608 x  32 0.639 BF</span><br><span class="line">   1 conv     64       3 x 3&#x2F; 2    608 x 608 x  32 -&gt;  304 x 304 x  64 3.407 BF</span><br><span class="line">   2 conv     64       1 x 1&#x2F; 1    304 x 304 x  64 -&gt;  304 x 304 x  64 0.757 BF</span><br><span class="line">   3 route  1                                      -&gt;  304 x 304 x  64 </span><br><span class="line">   4 conv     64       1 x 1&#x2F; 1    304 x 304 x  64 -&gt;  304 x 304 x  64 0.757 BF</span><br><span class="line">   5 conv     32       1 x 1&#x2F; 1    304 x 304 x  64 -&gt;  304 x 304 x  32 0.379 BF</span><br><span class="line">   6 conv     64       3 x 3&#x2F; 1    304 x 304 x  32 -&gt;  304 x 304 x  64 3.407 BF</span><br><span class="line">   7 Shortcut Layer: 4,  wt &#x3D; 0, wn &#x3D; 0, outputs: 304 x 304 x  64 0.006 BF</span><br><span class="line">   8 conv     64       1 x 1&#x2F; 1    304 x 304 x  64 -&gt;  304 x 304 x  64 0.757 BF</span><br><span class="line">   9 route  8 2                                    -&gt;  304 x 304 x 128 </span><br><span class="line">  10 conv     64       1 x 1&#x2F; 1    304 x 304 x 128 -&gt;  304 x 304 x  64 1.514 BF</span><br><span class="line">  11 conv    128       3 x 3&#x2F; 2    304 x 304 x  64 -&gt;  152 x 152 x 128 3.407 BF</span><br><span class="line">  12 conv     64       1 x 1&#x2F; 1    152 x 152 x 128 -&gt;  152 x 152 x  64 0.379 BF</span><br><span class="line">  13 route  11                                     -&gt;  152 x 152 x 128</span><br><span class="line">  14 conv     64       1 x 1&#x2F; 1    152 x 152 x 128 -&gt;  152 x 152 x  64 0.379 BF</span><br><span class="line">  15 conv     64       1 x 1&#x2F; 1    152 x 152 x  64 -&gt;  152 x 152 x  64 0.189 BF</span><br><span class="line">  16 conv     64       3 x 3&#x2F; 1    152 x 152 x  64 -&gt;  152 x 152 x  64 1.703 BF</span><br><span class="line">  17 Shortcut Layer: 14,  wt &#x3D; 0, wn &#x3D; 0, outputs: 152 x 152 x  64 0.001 BF</span><br><span class="line">  18 conv     64       1 x 1&#x2F; 1    152 x 152 x  64 -&gt;  152 x 152 x  64 0.189 BF</span><br><span class="line">  19 conv     64       3 x 3&#x2F; 1    152 x 152 x  64 -&gt;  152 x 152 x  64 1.703 BF</span><br><span class="line">  20 Shortcut Layer: 17,  wt &#x3D; 0, wn &#x3D; 0, outputs: 152 x 152 x  64 0.001 BF</span><br><span class="line">  21 conv     64       1 x 1&#x2F; 1    152 x 152 x  64 -&gt;  152 x 152 x  64 0.189 BF</span><br><span class="line">  22 route  21 12                                  -&gt;  152 x 152 x 128 </span><br><span class="line">  23 conv    128       1 x 1&#x2F; 1    152 x 152 x 128 -&gt;  152 x 152 x 128 0.757 BF</span><br><span class="line">  24 conv    256       3 x 3&#x2F; 2    152 x 152 x 128 -&gt;   76 x  76 x 256 3.407 BF</span><br><span class="line">  25 conv    128       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 128 0.379 BF</span><br><span class="line">  26 route  24                                     -&gt;   76 x  76 x 256</span><br><span class="line">  27 conv    128       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 128 0.379 BF</span><br><span class="line">  28 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  29 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  30 Shortcut Layer: 27,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  31 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  32 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  33 Shortcut Layer: 30,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  34 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  35 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  36 Shortcut Layer: 33,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  37 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  38 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  39 Shortcut Layer: 36,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  40 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  41 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  42 Shortcut Layer: 39,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  43 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  44 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  45 Shortcut Layer: 42,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  46 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  47 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  48 Shortcut Layer: 45,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  49 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  50 conv    128       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 1.703 BF</span><br><span class="line">  51 Shortcut Layer: 48,  wt &#x3D; 0, wn &#x3D; 0, outputs:  76 x  76 x 128 0.001 BF</span><br><span class="line">  52 conv    128       1 x 1&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 128 0.189 BF</span><br><span class="line">  53 route  52 25                                  -&gt;   76 x  76 x 256 </span><br><span class="line">  54 conv    256       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 256 0.757 BF</span><br><span class="line">  55 conv    512       3 x 3&#x2F; 2     76 x  76 x 256 -&gt;   38 x  38 x 512 3.407 BF</span><br><span class="line">  56 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line">  57 route  55                                     -&gt;   38 x  38 x 512</span><br><span class="line">  58 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line">  59 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  60 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  61 Shortcut Layer: 58,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  62 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  63 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  64 Shortcut Layer: 61,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  65 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  66 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  67 Shortcut Layer: 64,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  68 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  69 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  70 Shortcut Layer: 67,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  71 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  72 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  73 Shortcut Layer: 70,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  74 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  75 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  76 Shortcut Layer: 73,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  77 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  78 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  79 Shortcut Layer: 76,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  80 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  81 conv    256       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 1.703 BF</span><br><span class="line">  82 Shortcut Layer: 79,  wt &#x3D; 0, wn &#x3D; 0, outputs:  38 x  38 x 256 0.000 BF</span><br><span class="line">  83 conv    256       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 256 0.189 BF</span><br><span class="line">  84 route  83 56                                  -&gt;   38 x  38 x 512 </span><br><span class="line">  85 conv    512       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 512 0.757 BF</span><br><span class="line">  86 conv   1024       3 x 3&#x2F; 2     38 x  38 x 512 -&gt;   19 x  19 x1024 3.407 BF</span><br><span class="line">  87 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line">  88 route  86                                     -&gt;   19 x  19 x1024</span><br><span class="line">  89 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line">  90 conv    512       1 x 1&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.189 BF</span><br><span class="line">  91 conv    512       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 1.703 BF</span><br><span class="line">  92 Shortcut Layer: 89,  wt &#x3D; 0, wn &#x3D; 0, outputs:  19 x  19 x 512 0.000 BF</span><br><span class="line">  93 conv    512       1 x 1&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.189 BF</span><br><span class="line">  94 conv    512       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 1.703 BF</span><br><span class="line">  95 Shortcut Layer: 92,  wt &#x3D; 0, wn &#x3D; 0, outputs:  19 x  19 x 512 0.000 BF</span><br><span class="line">  96 conv    512       1 x 1&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.189 BF</span><br><span class="line">  97 conv    512       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 1.703 BF</span><br><span class="line">  98 Shortcut Layer: 95,  wt &#x3D; 0, wn &#x3D; 0, outputs:  19 x  19 x 512 0.000 BF</span><br><span class="line">  99 conv    512       1 x 1&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.189 BF</span><br><span class="line"> 100 conv    512       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 1.703 BF</span><br><span class="line"> 101 Shortcut Layer: 98,  wt &#x3D; 0, wn &#x3D; 0, outputs:  19 x  19 x 512 0.000 BF</span><br><span class="line"> 102 conv    512       1 x 1&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.189 BF</span><br><span class="line"> 103 route  102 87                                 -&gt;   19 x  19 x1024</span><br><span class="line"> 104 conv   1024       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x1024 0.757 BF</span><br><span class="line"> 105 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line"> 106 conv   1024       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x1024 3.407 BF</span><br><span class="line"> 107 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line"> 108 max                5x 5&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.005 BF</span><br><span class="line"> 109 route  107                                            -&gt;   19 x  19 x 512</span><br><span class="line"> 110 max                9x 9&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.015 BF</span><br><span class="line"> 111 route  107                                            -&gt;   19 x  19 x 512</span><br><span class="line"> 112 max               13x13&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 512 0.031 BF</span><br><span class="line"> 113 route  112 110 108 107                        -&gt;   19 x  19 x2048</span><br><span class="line"> 114 conv    512       1 x 1&#x2F; 1     19 x  19 x2048 -&gt;   19 x  19 x 512 0.757 BF</span><br><span class="line"> 115 conv   1024       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x1024 3.407 BF</span><br><span class="line"> 116 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line"> 117 conv    256       1 x 1&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x 256 0.095 BF</span><br><span class="line"> 118 upsample                 2x    19 x  19 x 256 -&gt;   38 x  38 x 256</span><br><span class="line"> 119 route  85                                     -&gt;   38 x  38 x 512</span><br><span class="line"> 120 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 121 route  120 118                                -&gt;   38 x  38 x 512 </span><br><span class="line"> 122 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 123 conv    512       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 512 3.407 BF</span><br><span class="line"> 124 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 125 conv    512       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 512 3.407 BF</span><br><span class="line"> 126 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 127 conv    128       1 x 1&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 128 0.095 BF</span><br><span class="line"> 128 upsample                 2x    38 x  38 x 128 -&gt;   76 x  76 x 128</span><br><span class="line"> 129 route  54                                     -&gt;   76 x  76 x 256</span><br><span class="line"> 130 conv    128       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 128 0.379 BF</span><br><span class="line"> 131 route  130 128                                -&gt;   76 x  76 x 256</span><br><span class="line"> 132 conv    128       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 128 0.379 BF</span><br><span class="line"> 133 conv    256       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 256 3.407 BF</span><br><span class="line"> 134 conv    128       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 128 0.379 BF</span><br><span class="line"> 135 conv    256       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 256 3.407 BF</span><br><span class="line"> 136 conv    128       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 128 0.379 BF</span><br><span class="line"> 137 conv    256       3 x 3&#x2F; 1     76 x  76 x 128 -&gt;   76 x  76 x 256 3.407 BF</span><br><span class="line"> 138 conv    255       1 x 1&#x2F; 1     76 x  76 x 256 -&gt;   76 x  76 x 255 0.754 BF</span><br><span class="line"> 139 yolo</span><br><span class="line">[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.20</span><br><span class="line">nms_kind: greedynms (1), beta &#x3D; 0.600000</span><br><span class="line"> 140 route  136                                            -&gt;   76 x  76 x 128</span><br><span class="line"> 141 conv    256       3 x 3&#x2F; 2     76 x  76 x 128 -&gt;   38 x  38 x 256 0.852 BF</span><br><span class="line"> 142 route  141 126                                -&gt;   38 x  38 x 512 </span><br><span class="line"> 143 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 144 conv    512       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 512 3.407 BF</span><br><span class="line"> 145 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 146 conv    512       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 512 3.407 BF</span><br><span class="line"> 147 conv    256       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 256 0.379 BF</span><br><span class="line"> 148 conv    512       3 x 3&#x2F; 1     38 x  38 x 256 -&gt;   38 x  38 x 512 3.407 BF</span><br><span class="line"> 149 conv    255       1 x 1&#x2F; 1     38 x  38 x 512 -&gt;   38 x  38 x 255 0.377 BF</span><br><span class="line"> 150 yolo</span><br><span class="line">[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.10</span><br><span class="line">nms_kind: greedynms (1), beta &#x3D; 0.600000</span><br><span class="line"> 151 route  147                                            -&gt;   38 x  38 x 256</span><br><span class="line"> 152 conv    512       3 x 3&#x2F; 2     38 x  38 x 256 -&gt;   19 x  19 x 512 0.852 BF</span><br><span class="line"> 153 route  152 116                                -&gt;   19 x  19 x1024</span><br><span class="line"> 154 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line"> 155 conv   1024       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x1024 3.407 BF</span><br><span class="line"> 156 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line"> 157 conv   1024       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x1024 3.407 BF</span><br><span class="line"> 158 conv    512       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 512 0.379 BF</span><br><span class="line"> 159 conv   1024       3 x 3&#x2F; 1     19 x  19 x 512 -&gt;   19 x  19 x1024 3.407 BF</span><br><span class="line"> 160 conv    255       1 x 1&#x2F; 1     19 x  19 x1024 -&gt;   19 x  19 x 255 0.189 BF</span><br><span class="line"> 161 yolo</span><br><span class="line">[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05</span><br><span class="line">nms_kind: greedynms (1), beta &#x3D; 0.600000</span><br><span class="line">Total BFLOPS 128.459</span><br><span class="line">avg_outputs &#x3D; 1068395</span><br><span class="line"> Allocate additional workspace_size &#x3D; 52.43 MB</span><br><span class="line">Loading weights from yolov4.weights...</span><br><span class="line"> seen 64, trained: 32032 K-images (500 Kilo-batches_64)</span><br><span class="line">Done! Loaded 162 layers from weights-file </span><br><span class="line"> Detection layer: 139 - type &#x3D; 28 </span><br><span class="line"> Detection layer: 150 - type &#x3D; 28 </span><br><span class="line"> Detection layer: 161 - type &#x3D; 28</span><br><span class="line">origin.jpg: Predicted in 184.923000 milli-seconds.</span><br><span class="line">person: 98%</span><br><span class="line">car: 94%</span><br><span class="line">truck: 31%</span><br><span class="line">car: 88%</span><br><span class="line">car: 99%</span><br><span class="line">person: 99%</span><br><span class="line">person: 37%</span><br><span class="line">car: 99%</span><br><span class="line">bus: 57%</span><br><span class="line">truck: 60%</span><br><span class="line">car: 99%</span><br></pre></td></tr></table></figure>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>可以看到预测结果，同时darknet里面也输出了GPU的信息<br><img src="/images/GraduationProject/predictions.jpg" alt="predictions"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>win10版本的darknet gpu版本安装完成。道路坎坷，记录下踩过的坑</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>毕业设计</tag>
        <tag>yolo</tag>
        <tag>darknet</tag>
      </tags>
  </entry>
</search>
